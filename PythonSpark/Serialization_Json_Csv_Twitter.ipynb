{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import pymongo\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from collections import namedtuple\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save json file, json serialization\n",
    "class IO_json(object):\n",
    "    \n",
    "    def __init__(self, filepath, filename, filesuffix='json'):\n",
    "        self.filepath = filepath        # /path/to/file  without the '/' at the end\n",
    "        self.filename = filename        # FILE_NAME\n",
    "        self.filesuffix = filesuffix\n",
    "        # self.file_io = os.path.join(dir_name, '.'.join((base_filename, filename_suffix)))\n",
    "\n",
    "    def save(self, data):\n",
    "        if os.path.isfile('{0}/{1}.{2}'.format(self.filepath, self.filename, self.filesuffix)):\n",
    "            # Append existing file\n",
    "            with io.open('{0}/{1}.{2}'.format(self.filepath, self.filename, self.filesuffix), 'a', encoding='utf-8') as f:\n",
    "                f.write(unicode(json.dumps(data, ensure_ascii= False))) \n",
    "                # In python 3, there is no \"unicode\" function \n",
    "                #f.write(json.dumps(data, ensure_ascii= False)) # create a \\\" escape char for \" in the saved file        \n",
    "        else:\n",
    "            # Create new file\n",
    "            with io.open('{0}/{1}.{2}'.format(self.filepath, self.filename, self.filesuffix), 'w', encoding='utf-8') as f:\n",
    "                f.write(unicode(json.dumps(data, ensure_ascii= False)))\n",
    "                # f.write(json.dumps(data, ensure_ascii= False))    \n",
    "\n",
    "    def load(self):\n",
    "        with io.open('{0}/{1}.{2}'.format(self.filepath, self.filename, self.filesuffix), encoding='utf-8') as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IO_csv(object):\n",
    "\n",
    "    def __init__(self, filepath, filename, filesuffix='csv'):\n",
    "        self.filepath = filepath       # /path/to/file  without the '/' at the end\n",
    "        self.filename = filename       # FILE_NAME\n",
    "        self.filesuffix = filesuffix\n",
    "         # self.file_io = os.path.join(dir_name, '.'.join((base_filename, filename_suffix)))\n",
    "\n",
    "    def save(self, data, NTname, fields):\n",
    "        # NTname = Name of the NamedTuple\n",
    "        # fields = header of CSV - list of the fields name\n",
    "        NTuple = namedtuple(NTname, fields)\n",
    "\n",
    "        if os.path.isfile('{0}/{1}.{2}'.format(self.filepath, self.filename, self.filesuffix)):\n",
    "            # Append existing file\n",
    "            with open('{0}/{1}.{2}'.format(self.filepath, self.filename, self.filesuffix), 'ab') as f:\n",
    "                writer = csv.writer(f)\n",
    "                \n",
    "                writer.writerows([row for row in map(NTuple._make, data)])\n",
    "                # list comprehension using map on the NamedTuple._make() iterable and the data file to be saved\n",
    "                # Notice writer.writerows and not writer.writerow (i.e. list of multiple rows sent to csv file\n",
    "        else:\n",
    "            # Create new file\n",
    "            with open('{0}/{1}.{2}'.format(self.filepath, self.filename, self.filesuffix), 'wb') as f:\n",
    "                writer = csv.writer(f)\n",
    "                \n",
    "                writer.writerow(fields) # fields = header of CSV - list of the fields name\n",
    "\n",
    "                writer.writerows([row for row in map(NTuple._make, data)])\n",
    "                #  list comprehension using map on the NamedTuple._make() iterable and the data file to be saved\n",
    "                # Notice writer.writerows and not writer.writerow (i.e. list of multiple rows sent to csv file\n",
    "\n",
    "    def load(self, NTname, fields):\n",
    "\n",
    "        NTuple = namedtuple(NTname, fields)\n",
    "\n",
    "        with open('{0}/{1}.{2}'.format(self.filepath, self.filename, self.filesuffix),'rU') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in map(NTuple._make, reader):\n",
    "                # Using map on the NamedTuple._make() iterable and the reader file to be loaded\n",
    "                yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient as MCli\n",
    "\n",
    "class IO_mongo(object):\n",
    "    conn={'host':'localhost', 'ip':'27017'}\n",
    "    \n",
    "    def __init__(self, db='twtr_db', coll='twtr_coll', **conn ):\n",
    "        # Connects to the MongoDB server\n",
    "        self.client = MCli(**conn)\n",
    "        self.db = self.client[db]\n",
    "        self.coll = self.db[coll]\n",
    "    \n",
    "    def save(self, data):\n",
    "        # Insert to collection in db\n",
    "        return self.coll.insert(data)\n",
    "    \n",
    "    def load(self, return_cursor=False, criteria=None, projection=None):\n",
    "        if criteria is None:\n",
    "            criteria = {}\n",
    "        if projection is None:\n",
    "            cursor = self.coll.find(criteria)\n",
    "        else:\n",
    "            cursor = self.coll.find(criteria, projection)\n",
    "        # Return a cursor for large amounts of data\n",
    "        if return_cursor:\n",
    "            return cursor\n",
    "        else:\n",
    "            return [ item for item in cursor ]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fields01 es schema o el header para utilizar csv\n",
    "fields01 = ['id', 'created_at', 'user_id', 'user_name', 'tweet_text', 'url']\n",
    "#create namedTuple\n",
    "Tweet01 = namedtuple('Tweet01',fields01)\n",
    "\n",
    "def parse_tweet(data):\n",
    "    #\"\"\"\n",
    "    #Parse a ``tweet`` from the given response data.\n",
    "    #\"\"\"\n",
    "    return Tweet01(id=data.get('id', None),\n",
    "                   created_at=data.get('created_at', None),\n",
    "                   user_id=data.get('user_id', None),\n",
    "                   user_name=data.get('user_name', None),\n",
    "                   tweet_text=data.get('tweet_text', None),\n",
    "                   url=data.get('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper Methods\n",
    "\n",
    "def parse_date(s):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(s,'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "\n",
    "def parse_geo(g,index):\n",
    "    try:\n",
    "        return str(g[\"geo\"][\"coordinates\"][index])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_tweet(statuses):\n",
    "    return [ {'id':status['id'],\n",
    "            'created_at' :parse_date(status['created_at']),\n",
    "            'user_id'    :status['user']['id'],\n",
    "            'user_name'  :status['user']['name'], \n",
    "            'tweet_text' :status['text'].encode('utf-8'),\n",
    "            'url':url['expanded_url']} \n",
    "            for status in statuses\n",
    "                for url in status['entities']['urls'] ]\n",
    "\n",
    "def extract_tweet_noURL(statuses):\n",
    "    return [ {'id':status['id'],\n",
    "              'created_at' :parse_date(status['created_at']),\n",
    "              'user_id'    :status['user']['id'],\n",
    "              'user_name'  :status['user']['name'],\n",
    "              'tweet_text' :status['text'].encode('utf-8') }\n",
    "                for status in statuses ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conection to twitter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import urlparse # python 2.7\n",
    "# import urllib # python 3.0\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwitterAPI(object):\n",
    "#\"\"\"\n",
    "#TwitterAPI class allows the Connection to Twitter via OAuth\n",
    "#once you have registered with Twitter and receive the\n",
    "#necessary credentials\n",
    "#\"\"\"\n",
    "    def __init__(self):\n",
    "        consumer_key = '7cafpvyNC3G5jBy7mA27bx9Oo'\n",
    "        consumer_secret = 'BnomaQh2WNblSaRrfmWZuKaWy60KOYqIr9Jy1gomFEWJWz1vr7'\n",
    "        access_token = '97539286-QWma2TH9cCBSLItuavZeoo11GCsiaDp7Lm9dpxrrE'\n",
    "        access_secret = 'sEcvyLDjlHpUmng7wo05iWAFXuLu29WXmPFXY5k7IZ0SN'\n",
    "        self.consumer_key = consumer_key\n",
    "        self.consumer_secret = consumer_secret\n",
    "        self.access_token = access_token\n",
    "        self.access_secret = access_secret\n",
    "        self.retries = 3\n",
    "        self.auth = twitter.oauth.OAuth(access_token, access_secret, consumer_key, consumer_secret)\n",
    "        self.api = twitter.Twitter(auth=self.auth)\n",
    "        \n",
    "        #IMPORTANTE se crea un log \n",
    "        # logger initialisation\n",
    "        appName = 'twt150530'\n",
    "        self.logger = logging.getLogger(appName)\n",
    "        # create console handler and set level to debug\n",
    "        logPath = '/home/juandavid/Documentos/archivosIpython/Chpater3/LogChapter3'\n",
    "        fileName = appName\n",
    "        fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(logPath, fileName))\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        fileHandler.setFormatter(formatter)\n",
    "        self.logger.addHandler(fileHandler)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        \n",
    "        # Save to JSON file initialisation\n",
    "        jsonFpath = '/home/juandavid/Documentos/archivosIpython/Chpater3/data'\n",
    "        jsonFname = 'twtr15053001'\n",
    "        self.jsonSaver = IO_json(jsonFpath, jsonFname)\n",
    "        \n",
    "        # Save to MongoDB Intitialisation\n",
    "        self.mongoSaver = IO_mongo(db='twtr01_db', coll='twtr01_coll')\n",
    "        \n",
    "    def searchTwitter(self, q, max_res=10,**kwargs):\n",
    "        search_results = self.api.search.tweets(q=q, count=10, **kwargs)\n",
    "        statuses = search_results['statuses']\n",
    "        max_results = min(1000, max_res)\n",
    "        \n",
    "        for _ in range(10):\n",
    "            try:\n",
    "                next_results = search_results['search_metadata']['next_results']\n",
    "                # self.logger.info('info' in searchTwitter - next_results:%s'% next_results[1:])\n",
    "            except KeyError as e:\n",
    "                self.logger.error('error in searchTwitter: %s' %(e))\n",
    "                break\n",
    "            \n",
    "            next_results = urlparse.parse_qsl(next_results[1:]) # python 2.7\n",
    "            #next_results = urllib.parse.parse_qsl(next_results[1:]) python 3.0\n",
    "            # self.logger.info('info' in searchTwitter - next_results[max_id]:', next_results[0:])\n",
    "            kwargs = dict(next_results)\n",
    "            # self.logger.info('info' in searchTwitter - next_results[max_id]:%s'% kwargs['max_id'])\n",
    "            search_results = self.api.search.tweets(**kwargs)\n",
    "            statuses += search_results['statuses']\n",
    "            self.saveTweets(search_results['statuses'])\n",
    "            if len(statuses) > max_results:\n",
    "                self.logger.info('info in searchTwitter - got %i tweets - max: %i' %(len(statuses), max_results))\n",
    "                break\n",
    "        return statuses\n",
    "        \n",
    "    def saveTweets(self, statuses):\n",
    "        # Saving to JSON File\n",
    "        self.jsonSaver.save(statuses)\n",
    "\n",
    "        # Saving to MongoDB\n",
    "        for s in statuses:\n",
    "            self.mongoSaver.save(s)\n",
    "    \n",
    "    def parseTweets(self, statuses):\n",
    "        return [(status['id'],\n",
    "            status['created_at'],\n",
    "            status['user']['id'],\n",
    "            status['user']['name'],\n",
    "            status['text'],\n",
    "            url['expanded_url'])\n",
    "                for status in statuses\n",
    "                    for url in status['entities']['urls'] ]\n",
    "    \n",
    "    def getTweets(self, q, max_res=10):\n",
    "        #\"\"\"\n",
    "        #Make a Twitter API call whilst managing rate limit and errors.\n",
    "        #\"\"\"\n",
    "        def handleError(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "            if wait_period > 3600: # Seconds\n",
    "                self.logger.error('Too many retries in getTweets: %s' %(e))\n",
    "                raise e\n",
    "            if e.e.code == 401:\n",
    "                self.logger.error('error 401 * Not Authorised * in getTweets: %s' %(e))\n",
    "                return None\n",
    "            elif e.e.code == 404:\n",
    "                self.logger.error('error 404 * Not Found * in getTweets: %s' %(e))\n",
    "                return None\n",
    "            elif e.e.code == 429:\n",
    "                self.logger.error('error 429 * API Rate Limit Exceeded * in getTweets: %s' %(e))\n",
    "                if sleep_when_rate_limited:\n",
    "                    self.logger.error('error 429 * Retrying in 15 minutes * in getTweets: %s' %(e))\n",
    "                    sys.stderr.flush()\n",
    "                    time.sleep(60*15 + 5)\n",
    "                    self.logger.info('error 429 * Retrying now * in getTweets: %s' %(e))\n",
    "                    return 2\n",
    "                else:\n",
    "                    raise e # Caller must handle the rate limiting issue\n",
    "            elif e.e.code in (500, 502, 503, 504):\n",
    "                self.logger.info('Encountered %i Error. Retrying in %i seconds' % (e.e.code, wait_period))\n",
    "                time.sleep(wait_period)\n",
    "                wait_period *= 1.5\n",
    "                return wait_period\n",
    "            else:\n",
    "                self.logger.error('Exit - aborting - %s' %(e))\n",
    "        while True:\n",
    "            try:\n",
    "                self.searchTwitter( q, max_res=10)\n",
    "            except twitter.api.TwitterHTTPError as e:\n",
    "                error_count = 0\n",
    "                wait_period = handleError(e, wait_period)\n",
    "                if wait_period is None:\n",
    "                    return  \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t= TwitterAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juandavid/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:14: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "INFO:twt150530:info in searchTwitter - got 20 tweets - max: 10\n"
     ]
    }
   ],
   "source": [
    "query = \"RondaRousey\"\n",
    "tsearch = t.searchTwitter(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if insert in os system\n",
    "# Check file exist in the path specified\n",
    "jsonFpath = '/home/juandavid/Documentos/archivosIpython/Chpater3/data'\n",
    "jsonFname = 'twtr15053001'\n",
    "jsonSuffix = 'json'\n",
    "os.path.isfile('{0}/{1}.{2}'.format(jsonFpath, jsonFname, jsonSuffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'contributors': None,\n",
      " u'coordinates': None,\n",
      " u'created_at': u'Fri Jan 01 14:59:57 +0000 2016',\n",
      " u'entities': {u'hashtags': [],\n",
      "               u'media': [{u'display_url': u'pic.twitter.com/fl49qzWIYO',\n",
      "                           u'expanded_url': u'http://twitter.com/Braddok2070/status/670606095178702848/photo/1',\n",
      "                           u'id': 670606093622493188,\n",
      "                           u'id_str': u'670606093622493188',\n",
      "                           u'indices': [30, 53],\n",
      "                           u'media_url': u'http://pbs.twimg.com/media/CU54sGqUwAQMF7Y.jpg',\n",
      "                           u'media_url_https': u'https://pbs.twimg.com/media/CU54sGqUwAQMF7Y.jpg',\n",
      "                           u'sizes': {u'large': {u'h': 375,\n",
      "                                                 u'resize': u'fit',\n",
      "                                                 u'w': 500},\n",
      "                                      u'medium': {u'h': 375,\n",
      "                                                  u'resize': u'fit',\n",
      "                                                  u'w': 500},\n",
      "                                      u'small': {u'h': 255,\n",
      "                                                 u'resize': u'fit',\n",
      "                                                 u'w': 340},\n",
      "                                      u'thumb': {u'h': 150,\n",
      "                                                 u'resize': u'crop',\n",
      "                                                 u'w': 150}},\n",
      "                           u'source_status_id': 670606095178702848,\n",
      "                           u'source_status_id_str': u'670606095178702848',\n",
      "                           u'source_user_id': 319579722,\n",
      "                           u'source_user_id_str': u'319579722',\n",
      "                           u'type': u'photo',\n",
      "                           u'url': u'https://t.co/fl49qzWIYO'}],\n",
      "               u'symbols': [],\n",
      "               u'urls': [],\n",
      "               u'user_mentions': [{u'id': 319579722,\n",
      "                                   u'id_str': u'319579722',\n",
      "                                   u'indices': [3, 15],\n",
      "                                   u'name': u'Albert Hubetsov',\n",
      "                                   u'screen_name': u'Braddok2070'},\n",
      "                                  {u'id': 310463188,\n",
      "                                   u'id_str': u'310463188',\n",
      "                                   u'indices': [17, 29],\n",
      "                                   u'name': u'Ronda Rousey',\n",
      "                                   u'screen_name': u'RondaRousey'}]},\n",
      " u'favorite_count': 0,\n",
      " u'favorited': False,\n",
      " u'geo': None,\n",
      " u'id': 682939321024774144,\n",
      " u'id_str': u'682939321024774144',\n",
      " u'in_reply_to_screen_name': None,\n",
      " u'in_reply_to_status_id': None,\n",
      " u'in_reply_to_status_id_str': None,\n",
      " u'in_reply_to_user_id': None,\n",
      " u'in_reply_to_user_id_str': None,\n",
      " u'is_quote_status': False,\n",
      " u'lang': u'und',\n",
      " u'metadata': {u'iso_language_code': u'und', u'result_type': u'recent'},\n",
      " u'place': None,\n",
      " u'possibly_sensitive': False,\n",
      " u'retweet_count': 2,\n",
      " u'retweeted': False,\n",
      " u'retweeted_status': {u'contributors': None,\n",
      "                       u'coordinates': None,\n",
      "                       u'created_at': u'Sat Nov 28 14:12:07 +0000 2015',\n",
      "                       u'entities': {u'hashtags': [],\n",
      "                                     u'media': [{u'display_url': u'pic.twitter.com/fl49qzWIYO',\n",
      "                                                 u'expanded_url': u'http://twitter.com/Braddok2070/status/670606095178702848/photo/1',\n",
      "                                                 u'id': 670606093622493188,\n",
      "                                                 u'id_str': u'670606093622493188',\n",
      "                                                 u'indices': [13, 36],\n",
      "                                                 u'media_url': u'http://pbs.twimg.com/media/CU54sGqUwAQMF7Y.jpg',\n",
      "                                                 u'media_url_https': u'https://pbs.twimg.com/media/CU54sGqUwAQMF7Y.jpg',\n",
      "                                                 u'sizes': {u'large': {u'h': 375,\n",
      "                                                                       u'resize': u'fit',\n",
      "                                                                       u'w': 500},\n",
      "                                                            u'medium': {u'h': 375,\n",
      "                                                                        u'resize': u'fit',\n",
      "                                                                        u'w': 500},\n",
      "                                                            u'small': {u'h': 255,\n",
      "                                                                       u'resize': u'fit',\n",
      "                                                                       u'w': 340},\n",
      "                                                            u'thumb': {u'h': 150,\n",
      "                                                                       u'resize': u'crop',\n",
      "                                                                       u'w': 150}},\n",
      "                                                 u'type': u'photo',\n",
      "                                                 u'url': u'https://t.co/fl49qzWIYO'}],\n",
      "                                     u'symbols': [],\n",
      "                                     u'urls': [],\n",
      "                                     u'user_mentions': [{u'id': 310463188,\n",
      "                                                         u'id_str': u'310463188',\n",
      "                                                         u'indices': [0,\n",
      "                                                                      12],\n",
      "                                                         u'name': u'Ronda Rousey',\n",
      "                                                         u'screen_name': u'RondaRousey'}]},\n",
      "                       u'favorite_count': 2,\n",
      "                       u'favorited': False,\n",
      "                       u'geo': None,\n",
      "                       u'id': 670606095178702848,\n",
      "                       u'id_str': u'670606095178702848',\n",
      "                       u'in_reply_to_screen_name': u'RondaRousey',\n",
      "                       u'in_reply_to_status_id': None,\n",
      "                       u'in_reply_to_status_id_str': None,\n",
      "                       u'in_reply_to_user_id': 310463188,\n",
      "                       u'in_reply_to_user_id_str': u'310463188',\n",
      "                       u'is_quote_status': False,\n",
      "                       u'lang': u'und',\n",
      "                       u'metadata': {u'iso_language_code': u'und',\n",
      "                                     u'result_type': u'recent'},\n",
      "                       u'place': None,\n",
      "                       u'possibly_sensitive': False,\n",
      "                       u'retweet_count': 2,\n",
      "                       u'retweeted': False,\n",
      "                       u'source': u'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>',\n",
      "                       u'text': u'@RondaRousey https://t.co/fl49qzWIYO',\n",
      "                       u'truncated': False,\n",
      "                       u'user': {u'contributors_enabled': False,\n",
      "                                 u'created_at': u'Sat Jun 18 11:00:41 +0000 2011',\n",
      "                                 u'default_profile': False,\n",
      "                                 u'default_profile_image': False,\n",
      "                                 u'description': u'- sale the REAL ESTATE in abroad for Russian people and not  only for them\\n www.\\u0434\\u043e\\u043c\\u043a\\u0432\\u0430\\u0440\\u0442\\u0438\\u0440\\u0430\\u0434\\u0430\\u0447\\u0430.\\u0440\\u0444',\n",
      "                                 u'entities': {u'description': {u'urls': []},\n",
      "                                               u'url': {u'urls': [{u'display_url': u'gson.uk',\n",
      "                                                                   u'expanded_url': u'https://gson.uk',\n",
      "                                                                   u'indices': [0,\n",
      "                                                                                23],\n",
      "                                                                   u'url': u'https://t.co/dMpomFHEPI'}]}},\n",
      "                                 u'favourites_count': 5262,\n",
      "                                 u'follow_request_sent': False,\n",
      "                                 u'followers_count': 2490,\n",
      "                                 u'following': False,\n",
      "                                 u'friends_count': 4999,\n",
      "                                 u'geo_enabled': False,\n",
      "                                 u'has_extended_profile': False,\n",
      "                                 u'id': 319579722,\n",
      "                                 u'id_str': u'319579722',\n",
      "                                 u'is_translation_enabled': False,\n",
      "                                 u'is_translator': False,\n",
      "                                 u'lang': u'ru',\n",
      "                                 u'listed_count': 22,\n",
      "                                 u'location': u'Moscow',\n",
      "                                 u'name': u'Albert Hubetsov',\n",
      "                                 u'notifications': False,\n",
      "                                 u'profile_background_color': u'0099B9',\n",
      "                                 u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/619094613702279168/dmIh3QTi.jpg',\n",
      "                                 u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/619094613702279168/dmIh3QTi.jpg',\n",
      "                                 u'profile_background_tile': False,\n",
      "                                 u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/319579722/1430311977',\n",
      "                                 u'profile_image_url': u'http://pbs.twimg.com/profile_images/3592175773/172f63f018be165ee365c6a91228fe82_normal.jpeg',\n",
      "                                 u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/3592175773/172f63f018be165ee365c6a91228fe82_normal.jpeg',\n",
      "                                 u'profile_link_color': u'0099B9',\n",
      "                                 u'profile_sidebar_border_color': u'000000',\n",
      "                                 u'profile_sidebar_fill_color': u'000000',\n",
      "                                 u'profile_text_color': u'000000',\n",
      "                                 u'profile_use_background_image': True,\n",
      "                                 u'protected': False,\n",
      "                                 u'screen_name': u'Braddok2070',\n",
      "                                 u'statuses_count': 17187,\n",
      "                                 u'time_zone': u'Quito',\n",
      "                                 u'url': u'https://t.co/dMpomFHEPI',\n",
      "                                 u'utc_offset': -18000,\n",
      "                                 u'verified': False}},\n",
      " u'source': u'<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
      " u'text': u'RT @Braddok2070: @RondaRousey https://t.co/fl49qzWIYO',\n",
      " u'truncated': False,\n",
      " u'user': {u'contributors_enabled': False,\n",
      "           u'created_at': u'Sun Sep 06 16:13:17 +0000 2015',\n",
      "           u'default_profile': True,\n",
      "           u'default_profile_image': False,\n",
      "           u'description': u'\\u2661Yo tengo un sue\\xf1o,  d\\xf3nde alg\\xfan d\\xeda todos los sere humanos, nos veamos como hermanos.  Mart\\xedn Luther king. Por fin somos libres!!!!\\u2661\\u2661\\u2661',\n",
      "           u'entities': {u'description': {u'urls': []}},\n",
      "           u'favourites_count': 72861,\n",
      "           u'follow_request_sent': False,\n",
      "           u'followers_count': 7097,\n",
      "           u'following': False,\n",
      "           u'friends_count': 3833,\n",
      "           u'geo_enabled': False,\n",
      "           u'has_extended_profile': False,\n",
      "           u'id': 3472261573,\n",
      "           u'id_str': u'3472261573',\n",
      "           u'is_translation_enabled': False,\n",
      "           u'is_translator': False,\n",
      "           u'lang': u'es',\n",
      "           u'listed_count': 314,\n",
      "           u'location': u'',\n",
      "           u'name': u'Maryori115',\n",
      "           u'notifications': False,\n",
      "           u'profile_background_color': u'C0DEED',\n",
      "           u'profile_background_image_url': u'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "           u'profile_background_image_url_https': u'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "           u'profile_background_tile': False,\n",
      "           u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/3472261573/1450380507',\n",
      "           u'profile_image_url': u'http://pbs.twimg.com/profile_images/643070321218617344/iP2f4u_C_normal.jpg',\n",
      "           u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/643070321218617344/iP2f4u_C_normal.jpg',\n",
      "           u'profile_link_color': u'0084B4',\n",
      "           u'profile_sidebar_border_color': u'C0DEED',\n",
      "           u'profile_sidebar_fill_color': u'DDEEF6',\n",
      "           u'profile_text_color': u'333333',\n",
      "           u'profile_use_background_image': True,\n",
      "           u'protected': False,\n",
      "           u'screen_name': u'maryori115',\n",
      "           u'statuses_count': 103239,\n",
      "           u'time_zone': None,\n",
      "           u'url': None,\n",
      "           u'utc_offset': None,\n",
      "           u'verified': False}}\n"
     ]
    }
   ],
   "source": [
    "# load tweets from file as a text string\n",
    "twts_ld = IO_json(jsonFpath, jsonFname).load()\n",
    "# Convert loaded tweets to Json\n",
    "twts_js = json.loads(twts_ld)\n",
    "#show firts tweet\n",
    "pp(twts_js[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'created_at': '2016-01-01 11:34:29',\n",
      "  'id': 682887613808775168,\n",
      "  'tweet_text': 'RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\xe2\\x80\\xa6',\n",
      "  'user_id': 598221206,\n",
      "  'user_name': u'Omar Agha'},\n",
      " {'created_at': '2016-01-01 11:31:01',\n",
      "  'id': 682886743159386112,\n",
      "  'tweet_text': '\"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark &amp; #ApacheStorm\" @infoQ https://t.co/CUqN0HL3BU #fastdata #bigdata #softwarearchitecture',\n",
      "  'user_id': 4516811547,\n",
      "  'user_name': u'Talks4Nerds'},\n",
      " {'created_at': '2016-01-01 10:50:51',\n",
      "  'id': 682876632688885760,\n",
      "  'tweet_text': 'RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\xe2\\x80\\xa6',\n",
      "  'user_id': 3588748576,\n",
      "  'user_name': u'Eccella Solutions'},\n",
      " {'created_at': '2016-01-01 10:14:58',\n",
      "  'id': 682867605540073472,\n",
      "  'tweet_text': '@noootsab @DataFellas @SparkNotebook @ApacheSpark well done Andy :)',\n",
      "  'user_id': 798116,\n",
      "  'user_name': u'Natalino Bus\\xe0'},\n",
      " {'created_at': '2016-01-01 10:03:20',\n",
      "  'id': 682864674577072128,\n",
      "  'tweet_text': 'RT @RomeoKienzler: 12.1.16: #Meetup on Spark, Scala &amp; Reactive by #IBM #Typesafe #Zalando https://t.co/RTOXe4frKe @ApacheSpark @scala_lang \\xe2\\x80\\xa6',\n",
      "  'user_id': 3377134096,\n",
      "  'user_name': u'J\\xf6rg Simon H\\xe4gele'},\n",
      " {'created_at': '2016-01-01 09:06:46',\n",
      "  'id': 682850440560701440,\n",
      "  'tweet_text': 'Succinct Spark: Queries on Compressed RDDs https://t.co/4CBGIbxqLq #apachespark #RDD #DStream #data #datascience',\n",
      "  'user_id': 74989078,\n",
      "  'user_name': u'GeekyNerdyMummy'},\n",
      " {'created_at': '2016-01-01 09:05:55',\n",
      "  'id': 682850226516963328,\n",
      "  'tweet_text': 'https://t.co/YndKkUszEJ #machinelearning #datascience #apachespark #data',\n",
      "  'user_id': 74989078,\n",
      "  'user_name': u'GeekyNerdyMummy'},\n",
      " {'created_at': '2016-01-01 09:02:46',\n",
      "  'id': 682849435735425024,\n",
      "  'tweet_text': 'RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\xe2\\x80\\xa6',\n",
      "  'user_id': 210865724,\n",
      "  'user_name': u'Corinne Chaumont'},\n",
      " {'created_at': '2016-01-01 08:19:50',\n",
      "  'id': 682838628494635008,\n",
      "  'tweet_text': 'RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\xe2\\x80\\xa6',\n",
      "  'user_id': 78281856,\n",
      "  'user_name': u'Muhammad Affan'},\n",
      " {'created_at': '2016-01-01 08:18:34',\n",
      "  'id': 682838312017592320,\n",
      "  'tweet_text': 'RT @RomeoKienzler: 12.1.16: #Meetup on Spark, Scala &amp; Reactive by #IBM #Typesafe #Zalando https://t.co/RTOXe4frKe @ApacheSpark @scala_lang \\xe2\\x80\\xa6',\n",
      "  'user_id': 1324426158,\n",
      "  'user_name': u'Barbara Jax'}]\n"
     ]
    }
   ],
   "source": [
    "# Extract key information from Tweets\n",
    "twts_ls_no_url = extract_tweet_noURL(twts_js)\n",
    "pp(twts_ls_no_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'created_at': '2016-01-01 11:34:29',\n",
      "  'id': 682887613808775168,\n",
      "  'tweet_text': 'RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\xe2\\x80\\xa6',\n",
      "  'url': u'http://bit.ly/1OIB1r9',\n",
      "  'user_id': 598221206,\n",
      "  'user_name': u'Omar Agha'},\n",
      " {'created_at': '2016-01-01 11:31:01',\n",
      "  'id': 682886743159386112,\n",
      "  'tweet_text': '\"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark &amp; #ApacheStorm\" @infoQ https://t.co/CUqN0HL3BU #fastdata #bigdata #softwarearchitecture',\n",
      "  'url': u'http://bit.ly/1R3E9UU',\n",
      "  'user_id': 4516811547,\n",
      "  'user_name': u'Talks4Nerds'},\n",
      " {'created_at': '2016-01-01 10:50:51',\n",
      "  'id': 682876632688885760,\n",
      "  'tweet_text': 'RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\xe2\\x80\\xa6',\n",
      "  'url': u'http://bit.ly/1OIB1r9',\n",
      "  'user_id': 3588748576,\n",
      "  'user_name': u'Eccella Solutions'},\n",
      " {'created_at': '2016-01-01 10:03:20',\n",
      "  'id': 682864674577072128,\n",
      "  'tweet_text': 'RT @RomeoKienzler: 12.1.16: #Meetup on Spark, Scala &amp; Reactive by #IBM #Typesafe #Zalando https://t.co/RTOXe4frKe @ApacheSpark @scala_lang \\xe2\\x80\\xa6',\n",
      "  'url': u'http://ow.ly/WvcOs',\n",
      "  'user_id': 3377134096,\n",
      "  'user_name': u'J\\xf6rg Simon H\\xe4gele'},\n",
      " {'created_at': '2016-01-01 09:06:46',\n",
      "  'id': 682850440560701440,\n",
      "  'tweet_text': 'Succinct Spark: Queries on Compressed RDDs https://t.co/4CBGIbxqLq #apachespark #RDD #DStream #data #datascience',\n",
      "  'url': u'https://amplab.cs.berkeley.edu/succinct-spark-queries-on-compressed-rdds/',\n",
      "  'user_id': 74989078,\n",
      "  'user_name': u'GeekyNerdyMummy'},\n",
      " {'created_at': '2016-01-01 09:05:55',\n",
      "  'id': 682850226516963328,\n",
      "  'tweet_text': 'https://t.co/YndKkUszEJ #machinelearning #datascience #apachespark #data',\n",
      "  'url': u'http://radar.oreilly.com/2015/07/6-reasons-why-i-like-keystoneml.html?imm_mid=0ddf30&cmp=em-data-na-na-newsltr_20151230',\n",
      "  'user_id': 74989078,\n",
      "  'user_name': u'GeekyNerdyMummy'},\n",
      " {'created_at': '2016-01-01 09:02:46',\n",
      "  'id': 682849435735425024,\n",
      "  'tweet_text': 'RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\xe2\\x80\\xa6',\n",
      "  'url': u'http://bit.ly/1OIB1r9',\n",
      "  'user_id': 210865724,\n",
      "  'user_name': u'Corinne Chaumont'},\n",
      " {'created_at': '2016-01-01 08:19:50',\n",
      "  'id': 682838628494635008,\n",
      "  'tweet_text': 'RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\xe2\\x80\\xa6',\n",
      "  'url': u'http://bit.ly/1OIB1r9',\n",
      "  'user_id': 78281856,\n",
      "  'user_name': u'Muhammad Affan'},\n",
      " {'created_at': '2016-01-01 08:18:34',\n",
      "  'id': 682838312017592320,\n",
      "  'tweet_text': 'RT @RomeoKienzler: 12.1.16: #Meetup on Spark, Scala &amp; Reactive by #IBM #Typesafe #Zalando https://t.co/RTOXe4frKe @ApacheSpark @scala_lang \\xe2\\x80\\xa6',\n",
      "  'url': u'http://ow.ly/WvcOs',\n",
      "  'user_id': 1324426158,\n",
      "  'user_name': u'Barbara Jax'}]\n"
     ]
    }
   ],
   "source": [
    "# Extract key information from Tweets\n",
    "twts_ls_url = extract_tweet(twts_js)\n",
    "pp(twts_ls_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet01(id=682876632688885760, created_at='2016-01-01 10:50:51', user_id=3588748576, user_name=u'Eccella Solutions', tweet_text='RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\xe2\\x80\\xa6', url=u'http://bit.ly/1OIB1r9')\n"
     ]
    }
   ],
   "source": [
    "# Create list of Tweets NamedTuple (by passing list of tweets through function parseTweets\n",
    "twts_nt_url =[parse_tweet(t) for t in twts_ls_url]\n",
    "print(twts_nt_url[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvFpath = '/home/juandavid/Documentos/archivosIpython/Chpater3/data'\n",
    "csvFname = 'twtr15051401'\n",
    "csvSuffix = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate the CSV IO object\n",
    "twts_csv = IO_csv(csvFpath, csvFname, csvSuffix)\n",
    "# Tweet NamedTuple definitions to be passed to CSV as parameters\n",
    "fields = ['id', 'created_at', 'user_id', 'user_name', 'tweet_text', 'url']\n",
    "Tweet_NT = 'Tweet01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\xf6' in position 1: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-770ef53cb3a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Executed the save twice - first in csv file create mode follwed by append mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtwts_csv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwts_nt_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTweet_NT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#lo salva aunque saca error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-2cbd40cb9de9>\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, data, NTname, fields)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0municode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# fields = header of CSV - list of the fields name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNTuple\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[1;31m#  list comprehension using map on the NamedTuple._make() iterable and the data file to be saved\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;31m# Notice writer.writerows and not writer.writerow (i.e. list of multiple rows sent to csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\xf6' in position 1: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# Executed the save twice - first in csv file create mode follwed by append mode\n",
    "twts_csv.save(twts_nt_url, Tweet_NT, fields)\n",
    "#lo salva solo una linea aunque saca error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read csv files\n",
    "twts_csv_read = [t for t in twts_csv.load(Tweet_NT, fields)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from blaze import Data, by, join, merge\n",
    "from odo import odo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>created_at</td>\n",
       "      <td>user_id</td>\n",
       "      <td>user_name</td>\n",
       "      <td>tweet_text</td>\n",
       "      <td>url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>682887613808775168</td>\n",
       "      <td>2016-01-01 11:34:29</td>\n",
       "      <td>598221206</td>\n",
       "      <td>Omar Agha</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "      <td>http://bit.ly/1OIB1r9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>682886743159386112</td>\n",
       "      <td>2016-01-01 11:31:01</td>\n",
       "      <td>4516811547</td>\n",
       "      <td>Talks4Nerds</td>\n",
       "      <td>\"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark ...</td>\n",
       "      <td>http://bit.ly/1R3E9UU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>682876632688885760</td>\n",
       "      <td>2016-01-01 10:50:51</td>\n",
       "      <td>3588748576</td>\n",
       "      <td>Eccella Solutions</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "      <td>http://bit.ly/1OIB1r9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           created_at     user_id          user_name  \\\n",
       "0                  id           created_at     user_id          user_name   \n",
       "1  682887613808775168  2016-01-01 11:34:29   598221206          Omar Agha   \n",
       "2  682886743159386112  2016-01-01 11:31:01  4516811547        Talks4Nerds   \n",
       "3  682876632688885760  2016-01-01 10:50:51  3588748576  Eccella Solutions   \n",
       "\n",
       "                                          tweet_text                    url  \n",
       "0                                         tweet_text                    url  \n",
       "1  RT @Talend: 2016 will be the year of #BigData ...  http://bit.ly/1OIB1r9  \n",
       "2  \"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark ...  http://bit.ly/1R3E9UU  \n",
       "3  RT @Talend: 2016 will be the year of #BigData ...  http://bit.ly/1OIB1r9  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create pandas dataframe and show\n",
    "twts_pd_df = pd.DataFrame(twts_csv_read, columns=Tweet01._fields)\n",
    "twts_pd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>682876632688885760</td>\n",
       "      <td>2016-01-01 10:50:51</td>\n",
       "      <td>4516811547</td>\n",
       "      <td>Omar Agha</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "      <td>http://bit.ly/1OIB1r9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id           created_at     user_id  user_name  \\\n",
       "count                    3                    3           3          3   \n",
       "unique                   3                    3           3          3   \n",
       "top     682876632688885760  2016-01-01 10:50:51  4516811547  Omar Agha   \n",
       "freq                     1                    1           1          1   \n",
       "\n",
       "                                               tweet_text  \\\n",
       "count                                                   3   \n",
       "unique                                                  2   \n",
       "top     RT @Talend: 2016 will be the year of #BigData ...   \n",
       "freq                                                    2   \n",
       "\n",
       "                          url  \n",
       "count                       3  \n",
       "unique                      2  \n",
       "top     http://bit.ly/1OIB1r9  \n",
       "freq                        2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove first row as it is a duplicate with the header\n",
    "twts_pd_df = twts_pd_df.drop(twts_pd_df.index[:1])\n",
    "twts_pd_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>682887613808775168</td>\n",
       "      <td>2016-01-01 11:34:29</td>\n",
       "      <td>598221206</td>\n",
       "      <td>Omar Agha</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "      <td>http://bit.ly/1OIB1r9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>682886743159386112</td>\n",
       "      <td>2016-01-01 11:31:01</td>\n",
       "      <td>4516811547</td>\n",
       "      <td>Talks4Nerds</td>\n",
       "      <td>\"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark ...</td>\n",
       "      <td>http://bit.ly/1R3E9UU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>682876632688885760</td>\n",
       "      <td>2016-01-01 10:50:51</td>\n",
       "      <td>3588748576</td>\n",
       "      <td>Eccella Solutions</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "      <td>http://bit.ly/1OIB1r9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                   id           created_at     user_id          user_name  \\\n",
       "1  682887613808775168  2016-01-01 11:34:29   598221206          Omar Agha   \n",
       "2  682886743159386112  2016-01-01 11:31:01  4516811547        Talks4Nerds   \n",
       "3  682876632688885760  2016-01-01 10:50:51  3588748576  Eccella Solutions   \n",
       "\n",
       "                                          tweet_text                    url  \n",
       "1  RT @Talend: 2016 will be the year of #BigData ...  http://bit.ly/1OIB1r9  \n",
       "2  \"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark ...  http://bit.ly/1R3E9UU  \n",
       "3  RT @Talend: 2016 will be the year of #BigData ...  http://bit.ly/1OIB1r9  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Blaze dataframe\n",
    "twts_bz_df = Data(twts_pd_df)\n",
    "twts_bz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>682887613808775168</td>\n",
       "      <td>2016-01-01 11:34:29</td>\n",
       "      <td>598221206</td>\n",
       "      <td>Omar Agha</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "      <td>http://bit.ly/1OIB1r9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>682886743159386112</td>\n",
       "      <td>2016-01-01 11:31:01</td>\n",
       "      <td>4516811547</td>\n",
       "      <td>Talks4Nerds</td>\n",
       "      <td>\"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark ...</td>\n",
       "      <td>http://bit.ly/1R3E9UU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>682876632688885760</td>\n",
       "      <td>2016-01-01 10:50:51</td>\n",
       "      <td>3588748576</td>\n",
       "      <td>Eccella Solutions</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "      <td>http://bit.ly/1OIB1r9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           created_at     user_id          user_name  \\\n",
       "1  682887613808775168  2016-01-01 11:34:29   598221206          Omar Agha   \n",
       "2  682886743159386112  2016-01-01 11:31:01  4516811547        Talks4Nerds   \n",
       "3  682876632688885760  2016-01-01 10:50:51  3588748576  Eccella Solutions   \n",
       "\n",
       "                                          tweet_text                    url  \n",
       "1  RT @Talend: 2016 will be the year of #BigData ...  http://bit.ly/1OIB1r9  \n",
       "2  \"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark ...  http://bit.ly/1R3E9UU  \n",
       "3  RT @Talend: 2016 will be the year of #BigData ...  http://bit.ly/1OIB1r9  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show data\n",
    "twts_bz_df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>682887613808775168</td>\n",
       "      <td>Omar Agha</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>682886743159386112</td>\n",
       "      <td>Talks4Nerds</td>\n",
       "      <td>\"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>682876632688885760</td>\n",
       "      <td>Eccella Solutions</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                   id          user_name  \\\n",
       "0  682887613808775168          Omar Agha   \n",
       "1  682886743159386112        Talks4Nerds   \n",
       "2  682876632688885760  Eccella Solutions   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  RT @Talend: 2016 will be the year of #BigData ...  \n",
       "1  \"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark ...  \n",
       "2  RT @Talend: 2016 will be the year of #BigData ...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract fields\n",
    "twts_bz_df[['id', 'user_name','tweet_text']].distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilizar odo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a blaze dataframe from the csv file created\n",
    "filepath   = csvFpath\n",
    "filename   = csvFname\n",
    "filesuffix = csvSuffix\n",
    "\n",
    "twts_df = Data('{0}/{1}.{2}'.format(filepath, filename, filesuffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>682887613808775168</td>\n",
       "      <td>2016-01-01 11:34:29</td>\n",
       "      <td>598221206</td>\n",
       "      <td>Omar Agha</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "      <td>http://bit.ly/1OIB1r9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                   id          created_at    user_id  user_name  \\\n",
       "0  682887613808775168 2016-01-01 11:34:29  598221206  Omar Agha   \n",
       "\n",
       "                                          tweet_text                    url  \n",
       "0  RT @Talend: 2016 will be the year of #BigData ...  http://bit.ly/1OIB1r9  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twts_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<odo.backends.json.JSONLines at 0x7f4ecbe6fbd0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get distinct rows\n",
    "twts_odo_distinct_df = twts_df[['id', 'user_name', 'user_id', 'tweet_text', 'created_at']].distinct()\n",
    "\n",
    "#filepath to save json \n",
    "jsonFpath = '/home/juandavid/Documentos/archivosIpython/Chpater3/data'\n",
    "jsonFname = 'twtr15051401_distinct' ## !! twtr15051401 reduced to only the distinct tweets\n",
    "jsonSuffix = 'json'\n",
    "\n",
    "#convert Blaze dataframe to json\n",
    "#Odo(source, target)\n",
    "odo(twts_odo_distinct_df, '{0}/{1}.{2}'.format(jsonFpath, jsonFname, jsonSuffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load json created with odo\n",
    "twts_odo_json_import = IO_json(jsonFpath, jsonFname).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{\"user_id\": 598221206, \"created_at\": \"2016-01-01T11:34:29Z\", \"user_name\": \"Omar Agha\", \"id\": 682887613808775168, \"tweet_text\": \"RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\\\u2026\"}\\n{\"user_id\": 4516811547, \"created_at\": \"2016-01-01T11:31:01Z\", \"user_name\": \"Talks4Nerds\", \"id\": 682886743159386112, \"tweet_text\": \"\\\\\"Yahoo! Benchmarks #ApacheFlink, #ApacheSpark &amp; #ApacheStorm\\\\\" @infoQ https://t.co/CUqN0HL3BU #fastdata #bigdata #softwarearchitecture\"}\\n{\"user_id\": 3588748576, \"created_at\": \"2016-01-01T10:50:51Z\", \"user_name\": \"Eccella Solutions\", \"id\": 682876632688885760, \"tweet_text\": \"RT @Talend: 2016 will be the year of #BigData &amp; #IoT! See how #Hadoop &amp; #ApacheSpark play in https://t.co/dKAi92BjRR @acole602 https://t.co\\\\u2026\"}\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twts_odo_json_import\n",
    "#no sirve utilizar los metodos extracttweet porque este json \n",
    "#tiene menos columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<odo.backends.csv.CSV at 0x7f4ecbdafc50>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de json to csv\n",
    "csvFpath  = '/home/juandavid/Documentos/archivosIpython/Chpater3/data'\n",
    "csvFname  = 'twtr15052401_all' ## !! twtr15051401 reduced to only the distinct tweets\n",
    "csvSuffix = 'csv'\n",
    "\n",
    "odo('{0}/{1}.{2}'.format(jsonFpath, jsonFname, jsonSuffix), '{0}/{1}.{2}'.format(csvFpath, csvFname, csvSuffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read csv created by odo\n",
    "twts_csv_odo_df = Data('{0}/{1}.{2}'.format(csvFpath, csvFname, csvSuffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 11:34:29</td>\n",
       "      <td>682887613808775168</td>\n",
       "      <td>RT @Talend: 2016 will be the year of #BigData ...</td>\n",
       "      <td>598221206</td>\n",
       "      <td>Omar Agha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "           created_at                  id  \\\n",
       "0 2016-01-01 11:34:29  682887613808775168   \n",
       "\n",
       "                                          tweet_text    user_id  user_name  \n",
       "0  RT @Talend: 2016 will be the year of #BigData ...  598221206  Omar Agha  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twts_csv_odo_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twts_sql_df_01 = sqlc.jsonFile(\"/home/juandavid/Documentos/archivosIpython/Chpater3/data/twtr15051401_distinct.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+----------+-----------------+\n",
      "|          created_at|                id|          tweet_text|   user_id|        user_name|\n",
      "+--------------------+------------------+--------------------+----------+-----------------+\n",
      "|2016-01-01T11:34:29Z|682887613808775168|RT @Talend: 2016 ...| 598221206|        Omar Agha|\n",
      "|2016-01-01T11:31:01Z|682886743159386112|\"Yahoo! Benchmark...|4516811547|      Talks4Nerds|\n",
      "|2016-01-01T10:50:51Z|682876632688885760|RT @Talend: 2016 ...|3588748576|Eccella Solutions|\n",
      "+--------------------+------------------+--------------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twts_sql_df_01.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|        user_name|\n",
      "+-----------------+\n",
      "|        Omar Agha|\n",
      "|      Talks4Nerds|\n",
      "|Eccella Solutions|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twts_sql_df_01.select('user_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+----------+-----------------+\n",
      "|          created_at|                id|          tweet_text|   user_id|        user_name|\n",
      "+--------------------+------------------+--------------------+----------+-----------------+\n",
      "|2016-01-01T11:31:01Z|682886743159386112|\"Yahoo! Benchmark...|4516811547|      Talks4Nerds|\n",
      "|2016-01-01T10:50:51Z|682876632688885760|RT @Talend: 2016 ...|3588748576|Eccella Solutions|\n",
      "+--------------------+------------------+--------------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create sql statements\n",
    "twts_sql_df_01.registerTempTable('tweets_01')\n",
    "twts_sql_df_01_selection = sqlc.sql(\"SELECT * FROM tweets_01 WHERE user_name <> 'Omar Agha'\")\n",
    "\n",
    "twts_sql_df_01_selection.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#READ THE ORIGINAL json file \n",
    "jsonFpath = '/home/juandavid/Documentos/archivosIpython/Chpater3/data'\n",
    "jsonFname = 'twtr15053001'\n",
    "jsonSuffix = 'json'\n",
    "infile = ('{0}/{1}.{2}'.format(jsonFpath, jsonFname, jsonSuffix))\n",
    "\n",
    "twts_sc_json_01 = sc.textFile(infile).map(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create with sql spark context\n",
    "tweets_sqlc_inf = sqlc.jsonFile(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contributors',\n",
       " 'coordinates',\n",
       " 'created_at',\n",
       " 'entities',\n",
       " 'favorite_count',\n",
       " 'favorited',\n",
       " 'geo',\n",
       " 'id',\n",
       " 'id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'in_reply_to_status_id',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'is_quote_status',\n",
       " 'lang',\n",
       " 'metadata',\n",
       " 'place',\n",
       " 'possibly_sensitive',\n",
       " 'retweet_count',\n",
       " 'retweeted',\n",
       " 'retweeted_status',\n",
       " 'source',\n",
       " 'text',\n",
       " 'truncated',\n",
       " 'user']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_sqlc_inf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract only the important twitter columns\n",
    "tweets_extract_sqlc = tweets_sqlc_inf[['created_at', 'id_str', 'text', 'user.id', 'user.name', 'entities.urls.expanded_url']].distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+----------+-------------------+--------------------+\n",
      "|          created_at|            id_str|                text|        id|               name|        expanded_url|\n",
      "+--------------------+------------------+--------------------+----------+-------------------+--------------------+\n",
      "|Fri Jan 01 14:40:...|682934358446059520|Lovely piece on @...|3072266542|    real girl sport|[https://sports.v...|\n",
      "|Fri Jan 01 14:39:...|682934293002338304|@RondaRousey @Bur...|3385234989|John Wesley Hendren|                  []|\n",
      "|Fri Jan 01 14:54:...|682937906814570496|RT @AnthonyMiyaza...|1244703216|          Bob Eager|[http://bit.ly/fi...|\n",
      "|Fri Jan 01 14:59:...|682939332173287424|RT @Braddok2070: ...|3472261573|         Maryori115|                  []|\n",
      "|Fri Jan 01 14:59:...|682939321024774144|RT @Braddok2070: ...|3472261573|         Maryori115|                  []|\n",
      "|Fri Jan 01 14:39:...|682934284936691713|RT @ArmbarNation:...|3377744919|   Ronda Rousey Fan|                  []|\n",
      "|Fri Jan 01 14:43:...|682935208606314496|@RondaRousey happ...| 392272755|          chearnest|                  []|\n",
      "|Fri Jan 01 14:55:...|682938216903761920|RT @kenanlawford9...|4495714581|               Neal|                  []|\n",
      "|Fri Jan 01 14:49:...|682936625094090753|RT @ArmbarNation:...| 124571498|   Tatiana carvalho|                  []|\n",
      "|Fri Jan 01 14:52:...|682937363820113921|Started reading t...| 572997470|          Amy Smith|                  []|\n",
      "+--------------------+------------------+--------------------+----------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_extract_sqlc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
